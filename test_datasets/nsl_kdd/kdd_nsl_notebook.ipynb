{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Static Testing with the NSL KDD Dataset\n",
    "\n",
    "The NSL KDD Dataset is an improved version of the KDD99 dataset. First we load the training set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt(\"KDDTrain+.txt\", delimiter=\",\", dtype=str)\n",
    "print(f'loaded {len(data)} training samples with {len(data[0])} features')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, the last line feature has to be deleted, since it shows how hard the prediction of a label is."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = np.delete(data, -1, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we calculate the correct feature extraction methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from feature_extraction.feature_extractor import FeatureExtractor, calculate_best_numeric_normalization\n",
    "\n",
    "feature_methods_path = 'kdd_nsl_extraction_methods.csv'\n",
    "feature_extractor = FeatureExtractor()\n",
    "if not feature_extractor.load_extraction_methods(feature_methods_path):\n",
    "    methods = feature_extractor.calculate_extraction_methods(data)\n",
    "    feature_extractor.save_extraction_methods(feature_methods_path)\n",
    "    print('methods calculated')\n",
    "\n",
    "\n",
    "    # Change some erroneous rows\n",
    "    def get_numeric_row(data: [], i: int) -> [str]:\n",
    "        return [float(d[i]) for d in data]\n",
    "\n",
    "\n",
    "    changes = [24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "    for i in changes:\n",
    "        m = calculate_best_numeric_normalization(get_numeric_row(data, i))\n",
    "        feature_extractor.change_method(i, m)\n",
    "    feature_extractor.save_extraction_methods(feature_methods_path)\n",
    "else:\n",
    "    print('methods loaded')\n",
    "data = [feature_extractor.transform(d) for d in data]\n",
    "print('data successfully extracted')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from feature_selection.genetic_algorithm_selector import reduce_bulk_features\n",
    "from feature_selection.correlation_selector import CorrelationSelector\n",
    "\n",
    "correlation_selector = CorrelationSelector()\n",
    "correlation_selector.train(data, list(range(2, 24)))\n",
    "features = correlation_selector.get_with_threshold(0.4)\n",
    "print(f'features = {features}')\n",
    "# features = [3, 11, 22, 24, 25, 28, 32, 33, 37, 38]\n",
    "features.append(len(data[0]) - 1)\n",
    "corr_data = reduce_bulk_features(data, features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_data = np.loadtxt(\"KDDTest+.txt\", delimiter=\",\", dtype=str)\n",
    "validation_data = np.delete(validation_data, -1, axis=1)\n",
    "validation_data = [feature_extractor.transform(d) for d in validation_data]\n",
    "\n",
    "def validate(classifier):\n",
    "    labels = [d[-1] for d in validation_data]\n",
    "    test_data = reduce_bulk_features(np.delete(validation_data, -1, axis=1), features)\n",
    "    classifications = [classifier.classify(sample) for sample in test_data]\n",
    "    for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        true_positive = []\n",
    "        true_negative = []\n",
    "        false_positive = []\n",
    "        false_negative = []\n",
    "        for i in range(len(classifications)):\n",
    "            test = classifications[i]\n",
    "            label = labels[i]\n",
    "            if label != 1:\n",
    "                if test >= threshold:\n",
    "                    true_positive.append(test)\n",
    "                else:\n",
    "                    false_negative.append(test)\n",
    "            else:\n",
    "                if test >= threshold:\n",
    "                    false_positive.append(test)\n",
    "                else:\n",
    "                    true_negative.append(test)\n",
    "        # create_hist(true_positive, 'true positive')\n",
    "        # create_hist(true_negative, 'true negative')\n",
    "        # create_hist(false_positive, 'false positive')\n",
    "        # create_hist(false_negative, 'false negative')\n",
    "        tp = len(true_positive)\n",
    "        tn = len(true_negative)\n",
    "        fp = len(false_positive)\n",
    "        fn = len(false_negative)\n",
    "        print(f'{classifier} with threshold {threshold}:')\n",
    "        print(f'Accuracy: {(tp + tn) / (tp + tn + fp + fn)}')\n",
    "        print(f'Detection Rate: {tp / (tp + fn)}')\n",
    "        print(f'FAR: {fp / (fp + tn)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find optimal hyperparameters for IFTSVM Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from classification.iftsvm_classifier import IFTSVMClassifier\n",
    "from training_process.iftsvm_training import IFTSVMTrainer\n",
    "iftsvm_classifier = IFTSVMClassifier(alpha=10, delta=5, C_1=0.5, C_2=1, C_3=0.5, C_4=0.1, kernel_size=100)\n",
    "if not iftsvm_classifier.load('iftsvm.csv'):\n",
    "    iftsvm_trainer = IFTSVMTrainer(corr_data, list(range(2, 24)), 'non-linear')\n",
    "    iftsvm_classifier = iftsvm_trainer.find_best_coefficients()\n",
    "    iftsvm_classifier.train(corr_data, list(range(2, 24)))\n",
    "    iftsvm_classifier.save('iftsvm.csv')\n",
    "validate(iftsvm_classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find optimal hyperparameters for ABC Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from classification.abc_classifier import ABCClassifier\n",
    "from training_process.abc_training import ABCTrainer\n",
    "abc_classifier = ABCClassifier()\n",
    "if not abc_classifier.load('abc.csv'):\n",
    "    abc_trainer = ABCTrainer(corr_data, list(range(2, 24)))\n",
    "    abc_classifier = abc_trainer.find_best_coefficients()\n",
    "    abc_classifier.train(corr_data, list(range(2, 24)))\n",
    "    abc_classifier.save('abc.csv')\n",
    "validate(abc_classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the model with a complete model trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime, time\n",
    "from training_process.model_trainer import train_model\n",
    "\n",
    "start = time.time()\n",
    "classifiers = [\n",
    "    iftsvm_classifier,\n",
    "    abc_classifier\n",
    "]\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "trained_model = train_model(classifiers=classifiers, data=data, positive_labels=list(range(2, 24)))\n",
    "print(f'finished after {datetime.timedelta(seconds=int(time.time() - start))}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start the validation process with the KDDTest+ dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def create_hist(hist_data, name):\n",
    "    plt.hist(hist_data, bins=np.arange(0, 1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.xlabel('membership degree')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "labels = [d[-1] for d in validation_data]\n",
    "test_data = np.delete(validation_data, -1, axis=1)\n",
    "classifications = [trained_model.classify(sample) for sample in test_data]\n",
    "true_positive = []\n",
    "true_negative = []\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "for i in range(len(classifications)):\n",
    "    label, mem_deg = classifications[i]\n",
    "    true_label = labels[i]\n",
    "    if true_label != 1:\n",
    "        if label == 0:\n",
    "            true_positive.append(mem_deg)\n",
    "        else:\n",
    "            false_negative.append(mem_deg)\n",
    "    else:\n",
    "        if label == 0:\n",
    "            false_positive.append(mem_deg)\n",
    "        else:\n",
    "            true_negative.append(mem_deg)\n",
    "create_hist(true_positive, 'true positive')\n",
    "create_hist(true_negative, 'true negative')\n",
    "create_hist(false_positive, 'false positive')\n",
    "create_hist(false_negative, 'false negative')\n",
    "tp = len(true_positive)\n",
    "tn = len(true_negative)\n",
    "fp = len(false_positive)\n",
    "fn = len(false_negative)\n",
    "print('result:')\n",
    "print(f'Accuracy: {(tp + tn) / (tp + tn + fp + fn)}')\n",
    "print(f'Detection Rate: {tp / (tp + fn)}')\n",
    "print(f'FAR: {fp / (fp + tn)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
