{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Static Testing with the UNSW NB15 Dataset\n",
    "\n",
    "The UNSW NB15 Dataset is a dataset containing real captured data from the university of new south wales in Sydney, Austraila from, the year 2015. First we load the training set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt(\"UNSW_NB15_training-set.csv\", delimiter=\",\", dtype=str)\n",
    "print(f'loaded {len(data)} training samples with {len(data[0])} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_unnecessary_data(data):\n",
    "    # First line with the titles\n",
    "    data = np.delete(data, 0, axis=0)\n",
    "    # id\n",
    "    data = np.delete(data, 0, axis=1)\n",
    "    # don't need label and category, remove label\n",
    "    data = np.delete(data, -1, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "data = remove_unnecessary_data(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we calculate the correct feature extraction methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from feature_extraction.feature_extractor import FeatureExtractor, calculate_best_numeric_normalization\n",
    "\n",
    "feature_methods_path = 'extraction_methods.csv'\n",
    "feature_extractor = FeatureExtractor()\n",
    "if not feature_extractor.load_extraction_methods(feature_methods_path):\n",
    "    methods = feature_extractor.calculate_extraction_methods(data)\n",
    "    feature_extractor.save_extraction_methods(feature_methods_path)\n",
    "    print('methods calculated')\n",
    "\n",
    "\n",
    "    # Change some erroneous rows\n",
    "    def get_numeric_row(data: [], i: int) -> [str]:\n",
    "        return [float(d[i]) for d in data]\n",
    "\n",
    "\n",
    "    # changes = [24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "    # for i in changes:\n",
    "    #     m = calculate_best_numeric_normalization(get_numeric_row(data, i))\n",
    "    #     feature_extractor.change_method(i, m)\n",
    "    feature_extractor.save_extraction_methods(feature_methods_path)\n",
    "else:\n",
    "    print('methods loaded')\n",
    "data = [feature_extractor.transform(d) for d in data]\n",
    "print('data successfully extracted')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from feature_selection.genetic_algorithm_selector import reduce_bulk_features\n",
    "from feature_selection.correlation_selector import CorrelationSelector\n",
    "\n",
    "correlation_selector = CorrelationSelector()\n",
    "correlation_selector.train(data, list(range(2, 24)))\n",
    "features = correlation_selector.get_with_threshold(0.4)\n",
    "\n",
    "print(f'features = {features}')\n",
    "# features = [0, 3, 9, 19, 23, 24, 25, 33, 34]\n",
    "features.append(len(data[0]) - 1)\n",
    "corr_data = reduce_bulk_features(data, features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_data = np.loadtxt(\"UNSW_NB15_testing-set.csv\", delimiter=\",\", dtype=str)\n",
    "validation_data = remove_unnecessary_data(validation_data)\n",
    "validation_data = [feature_extractor.transform(d) for d in validation_data]\n",
    "\n",
    "\n",
    "def validate(classifier):\n",
    "    labels = [d[-1] for d in validation_data]\n",
    "    test_data = reduce_bulk_features(np.delete(validation_data, -1, axis=1), features)\n",
    "    classifications = [classifier.classify(sample) for sample in test_data]\n",
    "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        true_positive = []\n",
    "        true_negative = []\n",
    "        false_positive = []\n",
    "        false_negative = []\n",
    "        for i in range(len(classifications)):\n",
    "            test = classifications[i]\n",
    "            label = labels[i]\n",
    "            if label != 1:\n",
    "                if test >= threshold:\n",
    "                    true_positive.append(test)\n",
    "                else:\n",
    "                    false_negative.append(test)\n",
    "            else:\n",
    "                if test >= threshold:\n",
    "                    false_positive.append(test)\n",
    "                else:\n",
    "                    true_negative.append(test)\n",
    "        tp = len(true_positive)\n",
    "        tn = len(true_negative)\n",
    "        fp = len(false_positive)\n",
    "        fn = len(false_negative)\n",
    "        print(f'{classifier}:')\n",
    "        print(f'threshold: {threshold}')\n",
    "        print(f'Accuracy: {(tp + tn) / (tp + tn + fp + fn)}')\n",
    "        print(f'Detection Rate: {tp / (tp + fn)}')\n",
    "        print(f'FAR: {fp / (fp + tn)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find optimal hyperparameters for IFTSVM Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import array_split\n",
    "from classification.iftsvm_classifier import IFTSVMClassifier\n",
    "from training_process.iftsvm_training import IFTSVMTrainer\n",
    "\n",
    "iftsvm_classifier = IFTSVMClassifier(alpha=50, delta=0, C_1=0.1, C_2=1, C_3=0.1, C_4=0.5, kernel_size=10)\n",
    "if not iftsvm_classifier.load('iftsvm.csv'):\n",
    "    iftsvm_trainer = IFTSVMTrainer(corr_data, list(range(2, 24)), 'non-linear')\n",
    "    iftsvm_classifier = iftsvm_trainer.find_best_coefficients()\n",
    "    iftsvm_classifier.train(array_split(corr_data, 10)[0], list(range(2, 24)))\n",
    "    iftsvm_classifier.save('iftsvm.csv')\n",
    "# validate(iftsvm_classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find optimal hyperparameters for ABC Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from classification.abc_classifier import ABCClassifier\n",
    "from training_process.abc_training import ABCTrainer\n",
    "\n",
    "abc_classifier = ABCClassifier(method='non-linear',\n",
    "                               generations=100, population_size=1000, cycle_numbers=1000,\n",
    "                               chosen_number=10, kernel_size=7, sight=10, fit_function='sight')\n",
    "if not abc_classifier.load('abc.csv'):\n",
    "    abc_trainer = ABCTrainer(corr_data, list(range(2, 24)))\n",
    "    abc_classifier = abc_trainer.find_best_coefficients()\n",
    "    abc_classifier.train(array_split(corr_data, 10)[0], list(range(2, 24)))\n",
    "    abc_classifier.save('abc.csv')\n",
    "# validate(abc_classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the model with a complete model trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime, time\n",
    "from training_process.model_trainer import train_model\n",
    "\n",
    "start = time.time()\n",
    "classifiers = [\n",
    "    iftsvm_classifier,\n",
    "    abc_classifier\n",
    "]\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "trained_model = train_model(classifiers=classifiers, data=data, positive_labels=list(range(2, 24)), selector_threshold=0.4, iterations=3)\n",
    "print(f'finished after {datetime.timedelta(seconds=int(time.time() - start))}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start the validation process with the KDDTest+ dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_data = remove_unnecessary_data(np.loadtxt(\"UNSW_NB15_testing-set.csv\", delimiter=\",\", dtype=str))\n",
    "print(f'loaded {len(validation_data)} test samples with {len(validation_data[0])} features')\n",
    "validation_data = [feature_extractor.transform(d) for d in validation_data]\n",
    "print('data successfully extracted')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [d[-1] for d in validation_data]\n",
    "test_data = np.delete(validation_data, -1, axis=1)\n",
    "classifications = [trained_model.classify(sample) for sample in test_data]\n",
    "true_positive = []\n",
    "true_negative = []\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "for i in range(len(classifications)):\n",
    "    label, mem_deg = classifications[i]\n",
    "    true_label = labels[i]\n",
    "    if true_label != 1:\n",
    "        if label == 0:\n",
    "            true_positive.append(mem_deg)\n",
    "        else:\n",
    "            false_negative.append(mem_deg)\n",
    "    else:\n",
    "        if label == 0:\n",
    "            false_positive.append(mem_deg)\n",
    "        else:\n",
    "            true_negative.append(mem_deg)\n",
    "tp = len(true_positive)\n",
    "tn = len(true_negative)\n",
    "fp = len(false_positive)\n",
    "fn = len(false_negative)\n",
    "print('result:')\n",
    "print(f'Accuracy: {(tp + tn) / (tp + tn + fp + fn)}')\n",
    "print(f'Detection Rate: {tp / (tp + fn)}')\n",
    "print(f'FAR: {fp / (fp + tn)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
