{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Static Testing with the CICFlow Dataset\n",
    "\n",
    "This dataset is real live data, which has been collected at the UNSW Canberra in 2015 over a few days. First we load the training set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_path = \"Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "training_data = np.loadtxt(training_path, delimiter=\",\", dtype=str)\n",
    "print(f'loaded {len(training_data)} training samples with {len(training_data[0])} features')\n",
    "\n",
    "file_paths = ['Friday-02-03-2018_TrafficForML_CICFlowMeter.csv', 'Friday-16-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "              'Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv', 'Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv',\n",
    "              'Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv', 'Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "              'Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "              'Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "              'Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv']\n",
    "for i in range(1, 21):\n",
    "    file_paths.append(f'Thursday-20-02-2018/Thursday-20-02-2018_TrafficForML_CICFlowMeter{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, remove the first line, which contains the labels, and the timestamp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_unnecessary_data(data):\n",
    "    data = np.delete(data, 2, axis=1)\n",
    "    data = np.delete(data, 0, axis=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "training_data = remove_unnecessary_data(training_data)\n",
    "print(training_data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we calculate the correct feature extraction methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from feature_extraction.feature_extractor import FeatureExtractor\n",
    "\n",
    "feature_methods_path = 'cic_flow_extraction_methods.csv'\n",
    "feature_extractor = FeatureExtractor()\n",
    "if not feature_extractor.load_extraction_methods(feature_methods_path):\n",
    "    methods = feature_extractor.calculate_extraction_methods(training_data)\n",
    "    feature_extractor.save_extraction_methods(feature_methods_path)\n",
    "    print('methods calculated')\n",
    "    feature_extractor.save_extraction_methods(feature_methods_path)\n",
    "else:\n",
    "    print('methods loaded')\n",
    "training_data = [feature_extractor.transform(d) for d in training_data]\n",
    "print('data successfully extracted')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from feature_selection.genetic_algorithm_selector import reduce_bulk_features\n",
    "from feature_selection.correlation_selector import CorrelationSelector\n",
    "\n",
    "correlation_selector = CorrelationSelector()\n",
    "correlation_selector.train(training_data, list(range(2, 24)))\n",
    "features = correlation_selector.get_with_threshold(0.4)\n",
    "if len(features) < 6:\n",
    "    features = correlation_selector.get_highest_ranked_features(6)\n",
    "# features = [8, 9, 13, 18, 23, 7]\n",
    "print(f'features = {features}')\n",
    "features.append(len(training_data[0]) - 1)\n",
    "corr_data = reduce_bulk_features(training_data, features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find optimal hyperparameters for IFTSVM Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_measures(classifier, test_data, threshold):\n",
    "    labels = [d[-1] for d in test_data]\n",
    "    test_data = reduce_bulk_features(np.delete(test_data, -1, axis=1), features)\n",
    "    classifications = [classifier.classify(sample) for sample in test_data]\n",
    "    true_positive = []\n",
    "    true_negative = []\n",
    "    false_positive = []\n",
    "    false_negative = []\n",
    "    for i in range(len(classifications)):\n",
    "        test = classifications[i]\n",
    "        label = labels[i]\n",
    "        if label != 1:\n",
    "            if test >= threshold:\n",
    "                true_positive.append(test)\n",
    "            else:\n",
    "                false_negative.append(test)\n",
    "        else:\n",
    "            if test >= threshold:\n",
    "                false_positive.append(test)\n",
    "            else:\n",
    "                true_negative.append(test)\n",
    "    return true_positive, true_negative, false_positive, false_negative\n",
    "\n",
    "\n",
    "def validate(classifier):\n",
    "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for path in file_paths:\n",
    "            print(f'add {path}')\n",
    "            validation_data = np.loadtxt(path, delimiter=\",\", dtype=str)\n",
    "            print(f'length data: {len(validation_data)}')\n",
    "            validation_data = [feature_extractor.transform(d) for d in validation_data]\n",
    "            ctp, ctn, cfp, cfn = calculate_measures(classifier, validation_data, threshold)\n",
    "            tp += len(ctp)\n",
    "            tn += len(ctn)\n",
    "            fp += len(cfp)\n",
    "            fn += len(cfn)\n",
    "        print(f'result for {classifier}:')\n",
    "        print(f'threshold: {threshold}')\n",
    "        print(f'Accuracy: {(tp + tn) / (tp + tn + fp + fn)}')\n",
    "        print(f'Detection Rate: {tp / (tp + fn)}')\n",
    "        print(f'FAR: {fp / (fp + tn)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from training_process.iftsvm_training import IFTSVMTrainer\n",
    "\n",
    "iftsvm_trainer = IFTSVMTrainer(corr_data, list(range(2, 24)), 'non-linear')\n",
    "iftsvm_classifier = iftsvm_trainer.find_best_coefficients()\n",
    "validate(iftsvm_classifier)\n",
    "iftsvm_classifier.save('iftsvm.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find optimal hyperparameters for ABC Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from training_process.abc_training import ABCTrainer\n",
    "\n",
    "abc_trainer = ABCTrainer(corr_data, list(range(2, 24)))\n",
    "abc_classifier = abc_trainer.find_best_coefficients()\n",
    "validate(abc_classifier)\n",
    "abc_classifier.save('abc_classifier.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the model with a complete model trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime, time\n",
    "from training_process.model_trainer import train_model\n",
    "\n",
    "start = time.time()\n",
    "classifiers = [\n",
    "    iftsvm_classifier,\n",
    "    abc_classifier\n",
    "]\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "trained_model = train_model(data=training_data, positive_labels=list(range(2, 24)), training_data_length=10000)\n",
    "print(f'finished after {datetime.timedelta(seconds=int(time.time() - start))}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start the validation process with the dataset of the other days"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def create_hist(hist_data, name):\n",
    "    plt.hist(hist_data, bins=np.arange(0, 1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.xlabel('membership degree')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_measures(test_data):\n",
    "    labels = [d[-1] for d in test_data]\n",
    "    test_data = np.delete(test_data, -1, axis=1)\n",
    "    classifications = [trained_model.classify(sample) for sample in test_data]\n",
    "    true_positive = []\n",
    "    true_negative = []\n",
    "    false_positive = []\n",
    "    false_negative = []\n",
    "    for i in range(len(classifications)):\n",
    "        label, mem_deg = classifications[i]\n",
    "        true_label = labels[i]\n",
    "        if true_label != 1:\n",
    "            if label == 0:\n",
    "                true_positive.append(mem_deg)\n",
    "            else:\n",
    "                false_negative.append(mem_deg)\n",
    "        else:\n",
    "            if label == 0:\n",
    "                false_positive.append(mem_deg)\n",
    "            else:\n",
    "                true_negative.append(mem_deg)\n",
    "    return true_positive, true_negative, false_positive, false_negative\n",
    "\n",
    "\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for path in file_paths:\n",
    "    print(f'add {path}')\n",
    "    validation_data = remove_unnecessary_data(np.loadtxt(path, delimiter=\",\", dtype=str))\n",
    "    print(f'length data: {len(validation_data)}')\n",
    "    validation_data = [feature_extractor.transform(d) for d in validation_data]\n",
    "    ctp, ctn, cfp, cfn = calculate_measures(validation_data)\n",
    "    tp += len(ctp)\n",
    "    tn += len(ctn)\n",
    "    fp += len(cfp)\n",
    "    fn += len(cfn)\n",
    "print('result:')\n",
    "print(f'Accuracy: {(tp + tn) / (tp + tn + fp + fn)}')\n",
    "print(f'Detection Rate: {tp / (tp + fn)}')\n",
    "print(f'FAR: {fp / (fp + tn)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
